# Pix2Pix - CÃ³digo Modular

Este proyecto implementa una red Pix2Pix (Image-to-Image Translation) organizada en mÃ³dulos para facilitar su uso y mantenimiento.

## Estructura del Proyecto

```
pix-2-pix_template/
â”‚
â”œâ”€â”€ src/                        # CÃ³digo fuente
â”‚   â”œâ”€â”€ dataset_loader.py       # ValidaciÃ³n y carga del dataset
â”‚   â”œâ”€â”€ network.py              # Arquitectura de la red (Generator, Discriminator)
â”‚   â”œâ”€â”€ training.py             # LÃ³gica de entrenamiento y evaluaciÃ³n
â”‚   â”œâ”€â”€ main.py                 # Script principal para entrenar
â”‚   â”œâ”€â”€ inference.py            # Script para realizar predicciones
â”‚   â””â”€â”€ organize_dataset.py     # Script para organizar imÃ¡genes en train/test
â”‚
â”œâ”€â”€ train.py                    # Script de entrada para entrenar
â”œâ”€â”€ predict.py                  # Script de entrada para inferencia
â”œâ”€â”€ organize.py                 # Script de entrada para organizar dataset
â”œâ”€â”€ run_script.sh               # ğŸ”§ Wrapper para ejecutar scripts fÃ¡cilmente
â”‚
â”œâ”€â”€ scripts/                    # ğŸ”§ Scripts de bash para automatizaciÃ³n
â”‚   â”œâ”€â”€ train_model.sh          # Entrenar un modelo individual
â”‚   â”œâ”€â”€ predict_model.sh        # Realizar predicciones
â”‚   â”œâ”€â”€ train_all_models.sh     # Entrenar todos los modelos
â”‚   â”œâ”€â”€ predict_all_models.sh   # Predecir con todos los modelos
â”‚   â”œâ”€â”€ quick_test.sh           # Prueba rÃ¡pida
â”‚   â””â”€â”€ README.md               # GuÃ­a de uso de scripts
â”‚
â”œâ”€â”€ dataset/                    # Datasets
â”œâ”€â”€ resultados/                 # Resultados de entrenamiento e inferencia
â”‚   â””â”€â”€ {nombre_modelo}/
â”‚       â”œâ”€â”€ imagenes_entrenamiento/  # ImÃ¡genes generadas durante entrenamiento
â”‚       â”œâ”€â”€ imagenes_prueba/         # Predicciones en test
â”‚       â”œâ”€â”€ weights/                 # Pesos del modelo
â”‚       â””â”€â”€ metricas/                # MÃ©tricas de evaluaciÃ³n
â”‚
â””â”€â”€ README.md                   # Este archivo
```

## MÃ³dulos

### 1. dataset_loader.py
**Funcionalidad:** ValidaciÃ³n y carga del dataset

- `DatasetValidator`: Valida que el dataset tenga la estructura correcta
  - Verifica carpetas `train/` y `test/`
  - Cuenta imÃ¡genes .png
  - Valida formato de imÃ¡genes

- `DatasetLoader`: Carga y preprocesa imÃ¡genes
  - Carga imÃ¡genes concatenadas (entrada|objetivo)
  - Aplica data augmentation para entrenamiento
  - Normaliza al rango [-1, 1]
  - Crea datasets de TensorFlow

### 2. network.py
**Funcionalidad:** Arquitectura de la red

- `Generator()`: Red U-Net generadora
  - Encoder con 8 capas de downsampling
  - Decoder con skip connections
  - Salida con activaciÃ³n tanh

- `Discriminator()`: Discriminador PatchGAN
  - Clasifica patches como reales o generados
  - Arquitectura convolucional

- `Pix2PixLoss`: Funciones de pÃ©rdida
  - PÃ©rdida del generador (GAN + L1)
  - PÃ©rdida del discriminador

### 3. training.py
**Funcionalidad:** Entrenamiento, evaluaciÃ³n y mÃ©tricas

- `Pix2PixTrainer`: Clase principal de entrenamiento
  - Train step con GradientTape
  - EvaluaciÃ³n con PSNR y SSIM
  - Guardado de checkpoints
  - IntegraciÃ³n con TensorBoard

- `Pix2PixInference`: Clase para inferencia
  - Carga de modelos entrenados
  - PredicciÃ³n sobre imÃ¡genes individuales o directorios
  - VisualizaciÃ³n de resultados

## Inicio RÃ¡pido

### OpciÃ³n 1: Usando Scripts (Recomendado) ğŸš€

Los scripts facilitan el entrenamiento y predicciÃ³n con configuraciÃ³n sencilla.

**En Windows (CMD/PowerShell):**
```cmd
REM 1. Organizar dataset
python organize.py

REM 2. Prueba rÃ¡pida
scripts\quick_test.bat canny

REM 3. Entrenar modelo
scripts\train_model.bat canny

REM 4. Hacer predicciones
scripts\predict_model.bat canny_model canny
```

**En Linux/Mac (Bash):**
```bash
# 1. Organizar dataset
python organize.py

# 2. Prueba rÃ¡pida
./scripts/quick_test.sh canny

# 3. Entrenar modelo
./scripts/train_model.sh canny

# 4. Hacer predicciones
./scripts/predict_model.sh canny_model canny
```

**Ver guÃ­as completas**:
- Windows: [scripts/WINDOWS.md](scripts/WINDOWS.md) ğŸªŸ
- Linux/Mac: [scripts/README.md](scripts/README.md) ğŸ§

### OpciÃ³n 2: Usando Python Directamente

## Organizar Dataset

Si tus imÃ¡genes no estÃ¡n organizadas en carpetas train/test, usa el script `organize.py`:

```bash
python organize.py
```

Este script:
- Lee los archivos `dataset/images_list/train_images.txt` y `test_images.txt`
- Organiza automÃ¡ticamente las imÃ¡genes en carpetas train/test para cada algoritmo
- Las imÃ¡genes se **copian** (no se mueven) a las carpetas correspondientes

## Uso con Python

### Estructura del Dataset

El dataset debe tener la siguiente estructura:

```
dataset/
â”œâ”€â”€ 1051 Redimensionadas/          # ImÃ¡genes ground truth
â”‚   â”œâ”€â”€ SEM Imaging_..._s0002.png
â”‚   â”œâ”€â”€ SEM Imaging_..._s0003.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ canny/                          # ImÃ¡genes de entrada (algoritmo canny)
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ SEM Imaging_..._s0004.png
â”‚   â”‚   â”œâ”€â”€ SEM Imaging_..._s0006.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ SEM Imaging_..._s0002.png
â”‚       â”œâ”€â”€ SEM Imaging_..._s0003.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ laplaciano/                     # Otro algoritmo
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â””â”€â”€ images_list/                    # Listas de divisiÃ³n train/test
    â”œâ”€â”€ train_images.txt
    â””â”€â”€ test_images.txt
```

**Importante:**
- Las imÃ¡genes de entrada y ground truth deben tener el **mismo nombre de archivo**
- El ground truth estÃ¡ en una carpeta separada (`1051 Redimensionadas`)
- Cada algoritmo (canny, laplaciano, etc.) tiene sus propias carpetas train/test

### 1. Entrenar un Modelo

#### Uso bÃ¡sico:
```bash
python train.py \
    --input-path dataset/canny \
    --ground-truth-path "dataset/1051 Redimensionadas"
```

#### Con visualizaciÃ³n de muestras:
```bash
python train.py \
    --input-path dataset/canny \
    --ground-truth-path "dataset/1051 Redimensionadas" \
    --show-samples
```

Esto mostrarÃ¡ una imagen de muestra de train y test (input y ground truth) antes de comenzar el entrenamiento.

#### ConfiguraciÃ³n completa:
```bash
python train.py \
    --input-path dataset/canny \
    --ground-truth-path "dataset/1051 Redimensionadas" \
    --dataset-name canny_model \
    --steps 500000 \
    --batch-size 1 \
    --learning-rate 2e-4 \
    --lambda-l1 100 \
    --eval-interval 1000 \
    --save-interval 5000 \
    --img-width 1024 \
    --img-height 413
```

#### Argumentos disponibles:

**Dataset:**
- `--input-path`: Ruta a la carpeta con imÃ¡genes de entrada [requerido]
- `--ground-truth-path`: Ruta a las imÃ¡genes ground truth (default: dataset/1051 Redimensionadas)
- `--dataset-name`: Nombre para guardar resultados
- `--img-width`: Ancho de las imÃ¡genes (default: 1024)
- `--img-height`: Alto de las imÃ¡genes (default: 413)

**Entrenamiento:**
- `--steps`: NÃºmero total de pasos (default: 500000)
- `--batch-size`: TamaÃ±o del batch (default: 1)
- `--learning-rate`: Tasa de aprendizaje (default: 2e-4)
- `--beta-1`: ParÃ¡metro beta_1 de Adam (default: 0.5)
- `--lambda-l1`: Peso de la pÃ©rdida L1 (default: 100)

**EvaluaciÃ³n:**
- `--eval-interval`: Intervalo para evaluar (default: 1000)
- `--save-interval`: Intervalo para guardar checkpoints (default: 5000)
- `--checkpoint-dir`: Directorio de checkpoints (default: ./training_checkpoints)
- `--log-dir`: Directorio de logs (default: ./logs)

**Opcionales:**
- `--restore-checkpoint`: Restaurar desde Ãºltimo checkpoint
- `--show-model-summary`: Mostrar resumen de los modelos
- `--show-samples`: Mostrar imÃ¡genes de muestra del dataset antes de entrenar
- `--no-augmentation`: Desactivar data augmentation (random crop y flip)

### 2. Realizar Predicciones

#### Predecir una imagen individual:
```bash
python predict.py \
    --weights resultados/canny_model/weights/best_generator_weights.h5 \
    --input-image test_image.png \
    --output-dir resultados/canny_model/predicciones \
    --visualize
```

#### Predecir un directorio completo:
```bash
python predict.py \
    --weights resultados/canny_model/weights/best_generator_weights.h5 \
    --input-dir dataset/test \
    --output-dir resultados/canny_model/predicciones
```

#### Evaluar en dataset de prueba:
```bash
python predict.py \
    --weights resultados/canny_model/weights/best_generator_weights.h5 \
    --test-dataset dataset/canny \
    --ground-truth-path "dataset/1051 Redimensionadas" \
    --output-dir resultados/canny_model
```

#### Argumentos disponibles:

**Modelo:**
- `--weights`: Ruta al archivo de pesos (.h5 o .keras) [requerido]
- `--img-width`: Ancho de las imÃ¡genes (default: 1024)
- `--img-height`: Alto de las imÃ¡genes (default: 413)

**Entrada:**
- `--input-image`: Imagen individual para predecir
- `--input-dir`: Directorio con imÃ¡genes
- `--test-dataset`: Dataset de prueba (carpeta con train/test, para mÃ©tricas)
- `--ground-truth-path`: Ruta a las imÃ¡genes ground truth (default: dataset/1051 Redimensionadas)

**Salida:**
- `--output-dir`: Directorio de salida (default: predictions)
- `--visualize`: Visualizar predicciones

### 3. Usar los MÃ³dulos en CÃ³digo Python

```python
import sys
sys.path.insert(0, 'src')

from dataset_loader import validate_and_load_dataset
from network import create_pix2pix_model, create_optimizers
from training import Pix2PixTrainer

# 1. Cargar dataset
train_ds, test_ds, loader = validate_and_load_dataset(
    input_path='dataset/canny',
    ground_truth_path='dataset/1051 Redimensionadas',
    img_width=1024,
    img_height=413
)

# 2. Crear modelo
generator, discriminator, loss_fn = create_pix2pix_model(
    img_height=413,
    img_width=1024,
    lambda_l1=100
)

# 3. Crear optimizadores
gen_opt, disc_opt = create_optimizers(learning_rate=2e-4)

# 4. Entrenar
trainer = Pix2PixTrainer(
    generator=generator,
    discriminator=discriminator,
    loss_fn=loss_fn,
    generator_optimizer=gen_opt,
    discriminator_optimizer=disc_opt,
    dataset_name='canny_model'
)

trainer.fit(train_ds, test_ds, steps=500000)
```

## Monitoreo con TensorBoard

Durante el entrenamiento, puedes monitorear las mÃ©tricas en tiempo real:

```bash
tensorboard --logdir logs/
```

Esto mostrarÃ¡:
- PÃ©rdida total del generador
- PÃ©rdida GAN del generador
- PÃ©rdida L1 del generador
- PÃ©rdida del discriminador

## Archivos Generados

Durante el entrenamiento se genera la siguiente estructura:

```
resultados/{dataset_name}/
â”œâ”€â”€ imagenes_entrenamiento/          # ImÃ¡genes generadas durante entrenamiento
â”‚   â””â”€â”€ epoch_{step}.jpg            # ComparaciÃ³n: Input | GT | PredicciÃ³n
â”‚
â”œâ”€â”€ imagenes_prueba/                 # Predicciones sobre dataset de prueba
â”‚   â”œâ”€â”€ {imagen1}.png               # Todas las imÃ¡genes generadas
â”‚   â”œâ”€â”€ {imagen2}.png
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ weights/                         # Pesos del modelo
â”‚   â”œâ”€â”€ best_generator_weights.h5   # Mejores pesos (PSNR + SSIM)
â”‚   â”œâ”€â”€ generator_final.keras       # Modelo generador completo
â”‚   â””â”€â”€ discriminator_final.keras   # Modelo discriminador completo
â”‚
â””â”€â”€ metricas/                        # MÃ©tricas de evaluaciÃ³n
    â”œâ”€â”€ individual_metrics.txt      # MÃ©tricas por cada imagen (PSNR, SSIM)
    â”œâ”€â”€ final_metrics_summary.txt   # Resumen final del entrenamiento
    â”œâ”€â”€ test_metrics_summary.txt    # Resumen de inferencia
    â””â”€â”€ metrics_step_{step}.txt     # MÃ©tricas en cada evaluaciÃ³n
```

Adicionalmente:
- `training_checkpoints/`: Checkpoints periÃ³dicos del modelo
- `logs/`: Logs de TensorBoard

**Ver detalles**: [ESTRUCTURA_RESULTADOS.md](ESTRUCTURA_RESULTADOS.md) para una explicaciÃ³n completa de cada archivo.

## Requisitos

Las dependencias se encuentran en `requirements_lightning.txt`:

```bash
pip install -r requirements_lightning.txt
```

Principales librerÃ­as:
- TensorFlow
- NumPy
- Matplotlib
- Pillow
- IPython

## GPU

El cÃ³digo detecta automÃ¡ticamente si hay GPUs disponibles y las utiliza para acelerar el entrenamiento.

## Notas

- Las imÃ¡genes deben estar en formato PNG
- El cÃ³digo espera imÃ¡genes en escala de grises (1 canal)
- Las dimensiones por defecto son 1024x413, pero se pueden ajustar
- El modelo guarda automÃ¡ticamente los mejores pesos basÃ¡ndose en PSNR + SSIM